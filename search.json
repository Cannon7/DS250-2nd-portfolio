[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - [asbestos prediction]",
    "section": "",
    "text": "paste your elevator pitch here The goal as requested by the customer, was to create a predictive model to find if houses were made in the 1980s or not. This model used the number of floors a house has to predict if the house was built before 1980. The precision average was 90% accuracy. With the data provided, we can accurately predict the time the house was built.\n\n\nShow the code\n# %%\n# Load data\ndwellings_ml = pd.read_csv('https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv')\n\ndwellings_ml.head()\n\n\n\n\n\n\n\n\n\nparcel\nabstrprd\nlivearea\nfinbsmnt\nbasement\nyrbuilt\ntotunits\nstories\nnocars\nnumbdrm\n...\narcstyle_THREE-STORY\narcstyle_TRI-LEVEL\narcstyle_TRI-LEVEL WITH BASEMENT\narcstyle_TWO AND HALF-STORY\narcstyle_TWO-STORY\nqualified_Q\nqualified_U\nstatus_I\nstatus_V\nbefore1980\n\n\n\n\n0\n00102-08-065-065\n1130\n1346\n0\n0\n2004\n1\n2\n2\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n1\n00102-08-073-073\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n2\n00102-08-078-078\n1130\n1346\n0\n0\n2005\n1\n2\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n3\n00102-08-081-081\n1130\n1146\n0\n0\n2005\n1\n1\n0\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n4\n00102-08-086-086\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n\n\n\n5 rows × 51 columns\n\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - [asbestos prediction]",
    "section": "",
    "text": "paste your elevator pitch here The goal as requested by the customer, was to create a predictive model to find if houses were made in the 1980s or not. This model used the number of floors a house has to predict if the house was built before 1980. The precision average was 90% accuracy. With the data provided, we can accurately predict the time the house was built.\n\n\nShow the code\n# %%\n# Load data\ndwellings_ml = pd.read_csv('https://github.com/byuidatascience/data4dwellings/raw/master/data-raw/dwellings_ml/dwellings_ml.csv')\n\ndwellings_ml.head()\n\n\n\n\n\n\n\n\n\nparcel\nabstrprd\nlivearea\nfinbsmnt\nbasement\nyrbuilt\ntotunits\nstories\nnocars\nnumbdrm\n...\narcstyle_THREE-STORY\narcstyle_TRI-LEVEL\narcstyle_TRI-LEVEL WITH BASEMENT\narcstyle_TWO AND HALF-STORY\narcstyle_TWO-STORY\nqualified_Q\nqualified_U\nstatus_I\nstatus_V\nbefore1980\n\n\n\n\n0\n00102-08-065-065\n1130\n1346\n0\n0\n2004\n1\n2\n2\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n1\n00102-08-073-073\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n2\n00102-08-078-078\n1130\n1346\n0\n0\n2005\n1\n2\n1\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n3\n00102-08-081-081\n1130\n1146\n0\n0\n2005\n1\n1\n0\n2\n...\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n\n\n4\n00102-08-086-086\n1130\n1249\n0\n0\n2005\n1\n1\n1\n2\n...\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n\n\n\n\n5 rows × 51 columns\n\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - [asbestos prediction]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCreate 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.\n\n\nShow the code\nbasements_totals = dwellings_ml.groupby('before1980')['basement'].sum().reset_index()\npre_1 = px.bar(basements_totals, x=\"before1980\", y=\"basement\", title=\"Houses before and after 1980 and corelation with garages.\")\n\n\nstories_totals = dwellings_ml.groupby('before1980')['stories'].sum().reset_index()\npre_2 = px.bar(stories_totals, x=\"before1980\", y=\"stories\", title=\"Houses before and after 1980 and corelation with stories.\")\n\n\nsqft_totals = dwellings_ml.groupby('before1980')['livearea'].sum().reset_index()\npre_3 = px.bar(sqft_totals, x=\"before1980\", y=\"livearea\", title=\"Houses before and after 1980 and corelation with sqr feet.\")\n\npre_1.show()\n\npre_2.show()\n\npre_3.show()\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\ninclude figures in chunks and discuss your findings in the figure.",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - [asbestos prediction]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.\nFirst we prepare the prediction by defining our X&Y train, test, and prediction values. I then set the data spread to be 66% learning, and 34% Testing.\n\n\nShow the code\n# %%\nX_pred = dwellings_ml.drop(dwellings_ml.filter(regex = 'before1980|yrbuilt|parcel').columns, axis = 1)\ny_pred = dwellings_ml.filter(regex = \"before1980\")\nX_train, X_test, y_train, y_test = train_test_split(\n    X_pred, y_pred, test_size = .34, random_state = 76)  \n\n\n\n\nShow the code\nclf = tree.DecisionTreeClassifier()\nclf = clf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_probs = clf.predict_proba(X_test)\n\n\n\n\nShow the code\ndf_features = pd.DataFrame(\n    {'f_names': X_train.columns, \n    'f_values': clf.feature_importances_}).sort_values('f_values', ascending = False)\n\n\n\n\nShow the code\n# %%\nprint(metrics.classification_report(y_pred, y_test))\n\n\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87      2963\n           1       0.91      0.93      0.92      4828\n\n    accuracy                           0.90      7791\n   macro avg       0.90      0.89      0.90      7791\nweighted avg       0.90      0.90      0.90      7791",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - [asbestos prediction]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.\n\n\nShow the code\n#%%\nchart = px.bar(df_features.head(3),\n    x='f_values', \n    y='f_names'\n)\n\nchart.update_layout(yaxis={'categoryorder':'total ascending'})\n\n\n                                                \n\n\n_The top function value was based on if the house was 1 story or not. This is logical, as it shows that houses made before 1980 are more likely to be only 1 floor. The 2nd most weighted function was based on garage type. This shows that house garage trends were changed in the late 80s The 3rd most weighted functionw as the amount of square feet a home has. This has a direct correlation with the amount of floors in a house.",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-4",
    "href": "Projects/project4.html#questiontask-4",
    "title": "Client Report - [asbestos prediction]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\n\n\nShow the code\n# %%\nprint(metrics.classification_report(y_pred, y_test))\n\n\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87      2963\n           1       0.91      0.93      0.92      4828\n\n    accuracy                           0.90      7791\n   macro avg       0.90      0.89      0.90      7791\nweighted avg       0.90      0.90      0.90      7791\n\n\n\nAccuracy: Indicates that the majority of predictions made by the model are correct. This is key in knowing if houses have asbestos. Precision: Indicates the model predicting a house was built before 1980, it is usually correct. This is valuable if misclassifying newer houses as older ones is costly. Recall: Indicates that the model can identifying houses built before 1980. This is crucial as it’s important not to miss any older houses, even if it means some newer houses are misclassified.",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - [flight delay index]",
    "section": "",
    "text": "In my findings, I report that the Atlanta, GA: Hartsfield-Jackson Atlanta International Airport is the worst in terms of delay amount and time. The delay of a flight is caused by weather 20-51% of the time. This depends on climate of course. The best time to travel would be November in terms of delay chance. For the optimal flight to avoid delays, you would want to fly in November at the Washington, DC: Washington Dulles International Airport.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - [flight delay index]",
    "section": "",
    "text": "In my findings, I report that the Atlanta, GA: Hartsfield-Jackson Atlanta International Airport is the worst in terms of delay amount and time. The delay of a flight is caused by weather 20-51% of the time. This depends on climate of course. The best time to travel would be November in terms of delay chance. For the optimal flight to avoid delays, you would want to fly in November at the Washington, DC: Washington Dulles International Airport.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - [flight delay index]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”)\nAll bad data in the set has been replaced by NaN. See below on line 2 of the table.\n\n\nRead and format data\n# Include and execute your code here\nclean_data = df.replace(-999, pd.NA).replace(\"n/a\", pd.NA).replace(\"\", pd.NA)\ndisplay(clean_data.head(3))\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500+\n&lt;NA&gt;\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\n&lt;NA&gt;\nJanuary\n2005.0\n12381\n414\n1058\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - [flight delay index]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays?\nAs desplayed in the chart below and by hovering, you can find that the Atlanta, GA: Hartsfield-Jackson Atlanta International Airport has had the most time delayed as well as most delays.\n\nDelay time\nDelay time total .cell execution_count=4}\n\nShow the code\nchart = px.scatter(clean_data, title=\"Delay time\", y=\"minutes_delayed_total\", hover_data= \"airport_name\")\ndisplay(chart)\n\n\n                                                \n\n\n::: {#cell-Delay count .cell execution_count=5}\n\nDelay count by index\nchart = px.scatter(clean_data, title=\"Delay count\",y=\"num_of_delays_total\", hover_data= \"airport_name\")\ndisplay(chart)\n\n\n                                                \n\n:::\n::: {#cell-Delay count to time .cell execution_count=6}\n\nDelay count to delay time\nchart = px.scatter(clean_data, title=\"Delay count to time\", x=\"minutes_delayed_total\",y=\"num_of_delays_total\", hover_data= \"airport_name\")\ndisplay(chart)\n\n\n                                                \n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - [flight delay index]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length?\nAs you can see by the chart below, November is the best time to fly in terms of chance of delay.\n::: {#cell-Delays by month .cell execution_count=7}\n\ndelay count by month\nchart = px.bar(clean_data, title=\"Delay count by month\", x=\"month\", y=\"num_of_delays_total\")\ndisplay(chart)\n\n\n                                                \n\n:::\nThere are less than 200k delays in November, compared to the over 350k delays that occur in July",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - [flight delay index]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nYour job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild).\ntype your results and analysis here\n\n\nShow the code\ndef month_check(month):\n    if pd.isna(month):\n        return 0.65  # Default value for missing months\n    elif month in [\"April\", \"August\"]:\n        return 0.4\n    else:\n        return 0.65\n#| code-summary: find the mean of delays\nlate_aircraft_mean = clean_data['num_of_delays_late_aircraft'].mean()\n#| code-summary: fill NaNs\nclean_data['num_of_delays_late_aircraft'].fillna(late_aircraft_mean, inplace=True)\n#| code-summary: creat the new column and do applied math\nclean_data[\"total_weather\"] = clean_data.apply(lambda row:((month_check(row[\"month\"]) * row[\"num_of_delays_nas\"]) + row[\"num_of_delays_weather\"] + (row[\"num_of_delays_late_aircraft\"] * 0.3)), axis=1)\n#| code-summary: round data to nearest integer \nclean_data['total_weather'] = clean_data['total_weather'].round().astype(int)\n#| code-summary: display first 5 entrees\ndisplay(clean_data.head(5))\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\ntotal_weather\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500+\n1109.104072\n4598\n10\n448\n8355\n116423.0\n104415\n207467.0\n297\n36931\n465533\n3769\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928.000000\n935\n11\n233\n3153\n53537.0\n70301\n36817.0\n363\n21779\n182797\n1119\n\n\n2\nIAD\n&lt;NA&gt;\nJanuary\n2005.0\n12381\n414\n1058.000000\n895\n4\n61\n2430\nNaN\n70919\n35660.0\n208\n4497\n134881\n960\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197\n2255.000000\n5415\n5\n306\n9178\n88691.0\n160811\n364382.0\n151\n24859\n638894\n4502\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572\n680.000000\n638\n7\n56\n1952\n27436.0\n38445\n21127.0\n218\n4326\n91552\n675",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - [flight delay index]",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\nAlthough the client requested a bargraph, I also included a scatter plot because of better readability. The airport with the most weather based delay would be the San Francisco, CA: San Francisco International Airport at 51.56% of delays being weather related. The airport with the least weather based delays would be the Salt Lake City, UT: Salt Lake City Airport at 20.56% of delays being weather related.\n\n\nRead and format data\n# Include and execute your code here\nchart = px.bar(clean_data, title=\"Weather Delay % of all delays\",y=clean_data[\"total_weather\"].astype(int) / clean_data[\"num_of_delays_total\"].astype(int), hover_data= \"airport_name\")\ndisplay(chart)\nchart2 = px.scatter(clean_data, title=\"Weather Delay % of all delays\",y=clean_data[\"total_weather\"].astype(int) / clean_data[\"num_of_delays_total\"].astype(int), hover_data= \"airport_name\")\ndisplay(chart2)",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - [US name history index]",
    "section": "",
    "text": "This project is a result of the query method in pandas. With the prompts provided, I have made graphs to visualize the data. Answering the questions, I have learned that names through time change in use based on fads/trends. The use of a name can go down and up in time.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - [US name history index]",
    "section": "",
    "text": "This project is a result of the query method in pandas. With the prompts provided, I have made graphs to visualize the data. Answering the questions, I have learned that names through time change in use based on fads/trends. The use of a name can go down and up in time.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Client Report - [US name history index]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\nMy Birthyear was about the halfway point of the peakvuse of the name Cannon.\n\n\nRead and format data\n# Include and execute your code here\ncannon = px.line(df.query('name == \"Cannon\"'), x=\"year\", y=\"Total\", title=\"Cannons naming history\")\ncannon.add_annotation(x=2005, y=208, text=\"My Birthyear\")\ncannon.show()\n\n\n                                                \n\n\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=4}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - [US name history index]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nI would guess the age of Brittany to be 33 because of the amount of people named Brittany in 1990. I would not guess 55-56 because of the 5 people named Brittany then.\n\n\nRead and format data\n# Include and execute your code here\nbrit = px.line(df.query('name == \"Brittany\"'), x=\"year\", y=\"Total\")\nbrit.add_annotation(x=1990, y=32562, text=\"33 to 34\")\nbrit.add_annotation(x=1968, y=5, text=\"55 to 56\")\nbrit.show()\n\n\n                                                \n\n\n::: {#cell-Q2 chart .cell execution_count=6}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=7}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - [US name history index]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nfrom 1920-1968 Mary was the most common name of the four. But in 1968, Paul passed slightly, than they were close ever since.The use of Martha has been lowest since 1954\n\n\nRead and format data\n# Include and execute your code here\nchristian = px.line(df.query('(name == \"Peter\" or name == \"Paul\" or name == \"Martha\" or name == \"Mary\") and 1919 &lt; year &lt; 2001'), x=\"year\", y=\"Total\", color=\"name\")\nchristian.show()\n\n\n                                                \n\n\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=9}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - [US name history index]",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nThe graph below shoes the history of all people named Anakin. The first starwars movie came out in 1977. Before 1998 there was never someone named Anakin in the database. The star wars movies lead to people being named Anakin\n\n\nRead and format data\n# Include and execute your code here\nstarwars = px.line(df.query('name == \"Anakin\"'), x=\"year\", y=\"Total\")\nstarwars.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - [MLB]",
    "section": "",
    "text": "The MLB is full of the worlds best baseball players. With this in mind, one might assume that the batters have incredible batting averages nearing the 80-90% range. This is not the case. While they do have the best batters, they also have the best pitchers. The data shows that the best hovers at around a 40% hit rate. This number can be staggering to those who don’t care for baseball.\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - [MLB]",
    "section": "",
    "text": "The MLB is full of the worlds best baseball players. With this in mind, one might assume that the batters have incredible batting averages nearing the 80-90% range. This is not the case. While they do have the best batters, they also have the best pitchers. The data shows that the best hovers at around a 40% hit rate. This number can be staggering to those who don’t care for baseball.\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - [MLB]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nRead and format data\n# Include and execute your code here\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\nquery = \"\"\" \n    SELECT\n        people.playerID,\n        collegeplaying.schoolID,\n        salaries.salary,\n        salaries.yearID,\n        salaries.teamID\n    FROM\n        people\n    INNER JOIN\n        collegeplaying ON people.playerID = collegeplaying.playerID\n    INNER JOIN\n        salaries ON people.playerID = salaries.playerID\n    WHERE\n        collegeplaying.schoolID = 'idbyuid'\n    ORDER BY\n        salaries.salary DESC;\n\"\"\"\ndf = pd.read_sql_query(query, con)\nprint(df)\ncon.close()\n\n\n     playerID schoolID     salary  yearID teamID\n0   lindsma01  idbyuid  4000000.0    2014    CHA\n1   lindsma01  idbyuid  4000000.0    2014    CHA\n2   lindsma01  idbyuid  3600000.0    2012    BAL\n3   lindsma01  idbyuid  3600000.0    2012    BAL\n4   lindsma01  idbyuid  2800000.0    2011    COL\n5   lindsma01  idbyuid  2800000.0    2011    COL\n6   lindsma01  idbyuid  2300000.0    2013    CHA\n7   lindsma01  idbyuid  2300000.0    2013    CHA\n8   lindsma01  idbyuid  1625000.0    2010    HOU\n9   lindsma01  idbyuid  1625000.0    2010    HOU\n10  stephga01  idbyuid  1025000.0    2001    SLN\n11  stephga01  idbyuid  1025000.0    2001    SLN\n12  stephga01  idbyuid   900000.0    2002    SLN\n13  stephga01  idbyuid   900000.0    2002    SLN\n14  stephga01  idbyuid   800000.0    2003    SLN\n15  stephga01  idbyuid   800000.0    2003    SLN\n16  stephga01  idbyuid   550000.0    2000    SLN\n17  stephga01  idbyuid   550000.0    2000    SLN\n18  lindsma01  idbyuid   410000.0    2009    FLO\n19  lindsma01  idbyuid   410000.0    2009    FLO\n20  lindsma01  idbyuid   395000.0    2008    FLO\n21  lindsma01  idbyuid   395000.0    2008    FLO\n22  lindsma01  idbyuid   380000.0    2007    FLO\n23  lindsma01  idbyuid   380000.0    2007    FLO\n24  stephga01  idbyuid   215000.0    1999    SLN\n25  stephga01  idbyuid   215000.0    1999    SLN\n26  stephga01  idbyuid   185000.0    1998    PHI\n27  stephga01  idbyuid   185000.0    1998    PHI\n28  stephga01  idbyuid   150000.0    1997    PHI\n29  stephga01  idbyuid   150000.0    1997    PHI",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - [MLB]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\nWrite an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\nThis code finds displays the problem with sortinf players that have only batted once. This leads to a perfect batting average, which has never happened among MLB batters.\n\n\nRead and format data\n# Include and execute your code here\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\nquery1 = \"\"\"\n    SELECT\n        batting.playerID,\n        batting.yearID,\n        CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT) AS batting_average\n    FROM\n        batting\n    WHERE\n        AB &gt; 0\n    GROUP BY\n        batting.playerID,\n        batting.yearID\n    ORDER BY\n        batting_average DESC,\n        batting.playerID ASC\n    LIMIT 5;\n\"\"\"\ndf = pd.read_sql_query(query1, con)\nprint(df)\ncon.close()\n\n\n    playerID  yearID  batting_average\n0  abernte02    1960              1.0\n1  abramge01    1923              1.0\n2  acklefr01    1964              1.0\n3  alanirj01    2019              1.0\n4  alberan01    2017              1.0\n\n\nUse the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\nWith a 10 bat requirement, the numbers are more possible, but not accurate, as players can bat at the end of a game and not be proficient.\n\n\nplot example\n# Include and execute your code here\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\nquery1 = \"\"\"\n    SELECT\n        batting.playerID,\n        batting.yearID,\n        CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT) AS batting_average\n    FROM\n        batting\n    WHERE\n        AB &gt; 0\n    GROUP BY\n        batting.playerID,\n        batting.yearID\n    HAVING\n        SUM(AB) &gt; 9\n    ORDER BY\n        batting_average DESC,\n        batting.playerID ASC\n    LIMIT 5;\n\"\"\"\ndf = pd.read_sql_query(query1, con)\nprint(df)\ncon.close()\n\n\n    playerID  yearID  batting_average\n0  nymanny01    1974         0.642857\n1  carsoma01    2013         0.636364\n2  altizda01    1910         0.600000\n3  silvech01    1948         0.571429\n4  puccige01    1930         0.562500\n\n\nNow calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results. These numbers are the most accurate of the 3 querys. The batting minimum almost ensures that the player is a batter in their role in the team. \n\n\ntable example\n# Include and execute your code here\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\nquery1 = \"\"\"\n    SELECT\n        batting.playerID,\n        CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT) AS batting_average\n    FROM\n        batting\n    WHERE\n        AB &gt; 0\n    GROUP BY\n        batting.playerID\n    HAVING\n        SUM(AB) &gt; 99\n    ORDER BY\n        batting_average DESC,\n        batting.playerID ASC\n    LIMIT 5;\n\"\"\"\ndf = pd.read_sql_query(query1, con)\nprint(df)\ncon.close()\n\n\n    playerID  batting_average\n0   cobbty01         0.366299\n1  barnero01         0.359682\n2  hornsro01         0.358497\n3  jacksjo01         0.355752\n4  meyerle01         0.355509",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - [MLB]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\nIn this graph, it compares both of the Sox teams in the MLB. The comparison is total home runs by that team. By the graph, you can see that the Red Sox have hit more home runs than the White Sox.\n\n\nRead and format data\n# Include and execute your code here\n\ncon = sqlite3.connect('lahmansbaseballdb.sqlite')\nquery2 = \"\"\"\n    SELECT\n        teams.name AS team,\n        SUM(CAST(batting.HR AS INTEGER)) AS homeruns\n    FROM\n        teams\n    JOIN\n        batting ON teams.teamID = batting.teamID\n    WHERE\n        teams.name IN (\"Boston Red Sox\", \"Chicago White Sox\")\n    GROUP BY\n        teams.name;\n\"\"\"\ndf = pd.read_sql_query(query2, con)\nchart = px.bar(df, x='team', y='homeruns', title=\"Sox Home Run Contest\")\nchart.show()\ncon.close()",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#elevator-pitch",
    "href": "Projects/project5.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-1",
    "href": "Projects/project5.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-2",
    "href": "Projects/project5.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-3",
    "href": "Projects/project5.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Cannon Roach’s CV",
    "section": "",
    "text": "Computer Scientist.\n\n\nHalf way to my bachelors degree.\n\n\nC#, Python, Java, Javascript, C++, and CSS/HTML\n\n\n\nRecursion, 3D game engines, and databases.\n\n\n\n\n2020 - 2024 Madison High School.\n2021 - now BYU Idaho\n\n\n\n2024 Certificate of Software engineering\n\n\n\n2022 - now ACW Cards, Idaho\n\nShipping\nSorting"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Cannon Roach’s CV",
    "section": "",
    "text": "Half way to my bachelors degree.\n\n\nC#, Python, Java, Javascript, C++, and CSS/HTML\n\n\n\nRecursion, 3D game engines, and databases."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Cannon Roach’s CV",
    "section": "",
    "text": "2020 - 2024 Madison High School.\n2021 - now BYU Idaho"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Cannon Roach’s CV",
    "section": "",
    "text": "2024 Certificate of Software engineering"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Cannon Roach’s CV",
    "section": "",
    "text": "2022 - now ACW Cards, Idaho\n\nShipping\nSorting"
  }
]